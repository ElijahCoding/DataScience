{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 'New York'],\n",
       "       [162597.7, 151377.59, 443898.53, 'California'],\n",
       "       [153441.51, 101145.55, 407934.54, 'Florida'],\n",
       "       [144372.41, 118671.85, 383199.62, 'New York'],\n",
       "       [142107.34, 91391.77, 366168.42, 'Florida'],\n",
       "       [131876.9, 99814.71, 362861.36, 'New York'],\n",
       "       [134615.46, 147198.87, 127716.82, 'California'],\n",
       "       [130298.13, 145530.06, 323876.68, 'Florida'],\n",
       "       [120542.52, 148718.95, 311613.29, 'New York'],\n",
       "       [123334.88, 108679.17, 304981.62, 'California'],\n",
       "       [101913.08, 110594.11, 229160.95, 'Florida'],\n",
       "       [100671.96, 91790.61, 249744.55, 'California'],\n",
       "       [93863.75, 127320.38, 249839.44, 'Florida'],\n",
       "       [91992.39, 135495.07, 252664.93, 'California'],\n",
       "       [119943.24, 156547.42, 256512.92, 'Florida'],\n",
       "       [114523.61, 122616.84, 261776.23, 'New York'],\n",
       "       [78013.11, 121597.55, 264346.06, 'California'],\n",
       "       [94657.16, 145077.58, 282574.31, 'New York'],\n",
       "       [91749.16, 114175.79, 294919.57, 'Florida'],\n",
       "       [86419.7, 153514.11, 0.0, 'New York'],\n",
       "       [76253.86, 113867.3, 298664.47, 'California'],\n",
       "       [78389.47, 153773.43, 299737.29, 'New York'],\n",
       "       [73994.56, 122782.75, 303319.26, 'Florida'],\n",
       "       [67532.53, 105751.03, 304768.73, 'Florida'],\n",
       "       [77044.01, 99281.34, 140574.81, 'New York'],\n",
       "       [64664.71, 139553.16, 137962.62, 'California'],\n",
       "       [75328.87, 144135.98, 134050.07, 'Florida'],\n",
       "       [72107.6, 127864.55, 353183.81, 'New York'],\n",
       "       [66051.52, 182645.56, 118148.2, 'Florida'],\n",
       "       [65605.48, 153032.06, 107138.38, 'New York'],\n",
       "       [61994.48, 115641.28, 91131.24, 'Florida'],\n",
       "       [61136.38, 152701.92, 88218.23, 'New York'],\n",
       "       [63408.86, 129219.61, 46085.25, 'California'],\n",
       "       [55493.95, 103057.49, 214634.81, 'Florida'],\n",
       "       [46426.07, 157693.92, 210797.67, 'California'],\n",
       "       [46014.02, 85047.44, 205517.64, 'New York'],\n",
       "       [28663.76, 127056.21, 201126.82, 'Florida'],\n",
       "       [44069.95, 51283.14, 197029.42, 'California'],\n",
       "       [20229.59, 65947.93, 185265.1, 'New York'],\n",
       "       [38558.51, 82982.09, 174999.3, 'California'],\n",
       "       [28754.33, 118546.05, 172795.67, 'California'],\n",
       "       [27892.92, 84710.77, 164470.71, 'Florida'],\n",
       "       [23640.93, 96189.63, 148001.11, 'California'],\n",
       "       [15505.73, 127382.3, 35534.17, 'New York'],\n",
       "       [22177.74, 154806.14, 28334.72, 'California'],\n",
       "       [1000.23, 124153.04, 1903.93, 'New York'],\n",
       "       [1315.46, 115816.21, 297114.46, 'Florida'],\n",
       "       [0.0, 135426.92, 0.0, 'California'],\n",
       "       [542.05, 51743.15, 0.0, 'New York'],\n",
       "       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../data/50_Startups.csv')\n",
    "\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elijah/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 1., 1., 0.],\n",
       "       [0., 0., 1., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [1., 1., 0., ..., 1., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 1., 0., ..., 1., 1., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features=[3]) # 3 features\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([112376.64128435, 107488.55827279, 112376.64128435, 112376.64128435,\n",
       "        112376.64128435, 119932.10905744, 119932.10905744, 119932.10905744,\n",
       "        112376.64128435, 112376.64128435]),\n",
       " array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "         81229.06,  97483.56, 110352.25, 166187.94]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr=np.ones((50, 1)).astype(int), values=X, axis=1)\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.68</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 28 Oct 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:26:34</td>     <th>  Log-Likelihood:    </th> <td> -595.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1195.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1199.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.887e+04</td> <td> 1329.062</td> <td>   21.723</td> <td> 0.000</td> <td> 2.62e+04</td> <td> 3.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 2.887e+04</td> <td> 1329.062</td> <td>   21.723</td> <td> 0.000</td> <td> 2.62e+04</td> <td> 3.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 2.887e+04</td> <td> 1329.062</td> <td>   21.723</td> <td> 0.000</td> <td> 2.62e+04</td> <td> 3.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 2.887e+04</td> <td> 1329.062</td> <td>   21.723</td> <td> 0.000</td> <td> 2.62e+04</td> <td> 3.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-4.343e+04</td> <td> 1.33e+04</td> <td>   -3.268</td> <td> 0.002</td> <td>-7.02e+04</td> <td>-1.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-4.343e+04</td> <td> 1.33e+04</td> <td>   -3.268</td> <td> 0.002</td> <td>-7.02e+04</td> <td>-1.67e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.784</td> <th>  Durbin-Watson:     </th> <td>   0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.676</td> <th>  Jarque-Bera (JB):  </th> <td>   0.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.277</td> <th>  Prob(JB):          </th> <td>   0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.727</td> <th>  Cond. No.          </th> <td>7.92e+32</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.19e-64. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.182\n",
       "Model:                            OLS   Adj. R-squared:                  0.165\n",
       "Method:                 Least Squares   F-statistic:                     10.68\n",
       "Date:                Mon, 28 Oct 2019   Prob (F-statistic):            0.00201\n",
       "Time:                        21:26:34   Log-Likelihood:                -595.63\n",
       "No. Observations:                  50   AIC:                             1195.\n",
       "Df Residuals:                      48   BIC:                             1199.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.887e+04   1329.062     21.723      0.000    2.62e+04    3.15e+04\n",
       "x1          2.887e+04   1329.062     21.723      0.000    2.62e+04    3.15e+04\n",
       "x2          2.887e+04   1329.062     21.723      0.000    2.62e+04    3.15e+04\n",
       "x3          2.887e+04   1329.062     21.723      0.000    2.62e+04    3.15e+04\n",
       "x4         -4.343e+04   1.33e+04     -3.268      0.002   -7.02e+04   -1.67e+04\n",
       "x5         -4.343e+04   1.33e+04     -3.268      0.002   -7.02e+04   -1.67e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.784   Durbin-Watson:                   0.316\n",
       "Prob(Omnibus):                  0.676   Jarque-Bera (JB):                0.796\n",
       "Skew:                           0.277   Prob(JB):                        0.672\n",
       "Kurtosis:                       2.727   Cond. No.                     7.92e+32\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.19e-64. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "regressor_OLS = OLS(endog=y, exog=X_opt).fit()\n",
    "\n",
    "regressor_OLS.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
