{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score of 4 or 5\n",
    "            return Sentiment.POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/sentiment/books_small.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "reviews[5].sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2007)\t0.20155461003908146\n",
      "  (0, 3545)\t0.09152360145738062\n",
      "  (0, 5197)\t0.20786775381390304\n",
      "  (0, 1515)\t0.24081563602839037\n",
      "  (0, 539)\t0.2795844985810354\n",
      "  (0, 7353)\t0.19986187253464202\n",
      "  (0, 2895)\t0.36946021882113367\n",
      "  (0, 6593)\t0.11098821327231712\n",
      "  (0, 6475)\t0.29281825356337265\n",
      "  (0, 1558)\t0.348387812231681\n",
      "  (0, 3054)\t0.1552116262620815\n",
      "  (0, 562)\t0.17938877649953142\n",
      "  (0, 6595)\t0.07218827779667952\n",
      "  (0, 1800)\t0.3400250782774752\n",
      "  (0, 350)\t0.16011186063775978\n",
      "  (0, 1148)\t0.1612216085384897\n",
      "  (0, 7086)\t0.3834351360039767\n",
      "  (1, 1494)\t0.15591333181975053\n",
      "  (1, 873)\t0.15784295329054357\n",
      "  (1, 3662)\t0.08789184786305634\n",
      "  (1, 2545)\t0.14763819739564865\n",
      "  (1, 3874)\t0.18779758605854352\n",
      "  (1, 2722)\t0.08236785186367496\n",
      "  (1, 4595)\t0.15784295329054357\n",
      "  (1, 6060)\t0.07780690207478286\n",
      "  :\t:\n",
      "  (669, 5899)\t0.1386555682825347\n",
      "  (669, 4841)\t0.06080823508144671\n",
      "  (669, 7133)\t0.02507626035207097\n",
      "  (669, 6592)\t0.06282617307554751\n",
      "  (669, 4612)\t0.030916375427241714\n",
      "  (669, 6709)\t0.055385413390901965\n",
      "  (669, 660)\t0.030987879997010533\n",
      "  (669, 7280)\t0.05328528027702418\n",
      "  (669, 2643)\t0.04978175149762001\n",
      "  (669, 7260)\t0.07950182375479722\n",
      "  (669, 4595)\t0.06435714931089347\n",
      "  (669, 6060)\t0.06344826056349344\n",
      "  (669, 2444)\t0.15107837197044416\n",
      "  (669, 4582)\t0.09677961919973371\n",
      "  (669, 342)\t0.10399167621190103\n",
      "  (669, 3534)\t0.13540006370212476\n",
      "  (669, 6632)\t0.09347307533006656\n",
      "  (669, 2007)\t0.04429874153926932\n",
      "  (669, 3545)\t0.18103988434825216\n",
      "  (669, 5197)\t0.045686277772386694\n",
      "  (669, 7353)\t0.04392670270975086\n",
      "  (669, 6593)\t0.14636147015547818\n",
      "  (669, 3054)\t0.13645293877109374\n",
      "  (669, 6595)\t0.07932961343975256\n",
      "  (669, 350)\t0.15835605390890117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# This book is great !\n",
    "# This book was so bad\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# vectorizer.fit(train_x)\n",
    "# train_x_vectors = vectorizer.transform(train_x)\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
